<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The NickEvents Blog</title>
    <link>https://evann362.github.io/</link>
    <description>Recent content on The NickEvents Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Nov 2025 00:10:37 +0100</lastBuildDate>
    <atom:link href="https://evann362.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Jardin de Math XR Experience</title>
      <link>https://evann362.github.io/posts/jardindmathxr/</link>
      <pubDate>Tue, 04 Nov 2025 00:10:37 +0100</pubDate>
      <guid>https://evann362.github.io/posts/jardindmathxr/</guid>
      <description>&lt;p&gt;Objective: Create an immersive experience into a garden with geometry that is both lively and mathematical. In the world of geometry there are various iconic forms that we feel everyone should know about such as a Poly�dre de Szilassi, Pyramid of Egypt, or a dodecahedron star. They explain much of how the world around us, especially nature, has repeating mathematical patterns that help us to create. Using 3d models and animations created in Blender imported then into Unity game engine for the Meta Quest 3 Headset. It�s meant to be a shared experience for groups of 3-4 with the option to enjoy while riding a hovercart similar to Mario Kart.&#xA;&#xD;&#xA;&lt;div class=&#34;video&#34;&gt;&#xD;&#xA;  &lt;iframe src=&#34;https://www.youtube.com/embed/TOuTHEyxy9Q?controls=1&amp;rel=0&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&lt;/p&gt;</description>
    </item>
    <item>
      <title>ParcVilleteSoundscape</title>
      <link>https://evann362.github.io/posts/parcvilletesoundscape/</link>
      <pubDate>Mon, 27 Oct 2025 18:13:16 +0100</pubDate>
      <guid>https://evann362.github.io/posts/parcvilletesoundscape/</guid>
      <description>&lt;p&gt;I reconstructed some of the geometry of the parc de la Villette in 3d form and attached certain forms to react based on the sound I collected from the Park. Thus sound triggers geometry. I experimented a light more than usual within the 3d software Blender especially with its Evee render.&#xA;&lt;strong&gt;Soundscape with shaders&lt;/strong&gt; &lt;em&gt;DigitalZ00&lt;/em&gt;&lt;/p&gt;&#xA;&#xD;&#xA;&lt;div class=&#34;video&#34;&gt;&#xD;&#xA;  &lt;iframe src=&#34;https://www.youtube.com/embed/3am9Jz6s29w?controls=1&amp;rel=0&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;&#xD;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Controlling the Mist</title>
      <link>https://evann362.github.io/posts/xrdev04/</link>
      <pubDate>Thu, 04 Jul 2024 00:10:37 +0100</pubDate>
      <guid>https://evann362.github.io/posts/xrdev04/</guid>
      <description>&lt;p&gt;Controlling the Mist&#xA;In my mission of using Touchdesigner(TD) for more interactive experiences, I created a VR experience for the Meta Quest headset. At the moment TD only supported virtual interactions and not AR interaction for the Quest headsets.&#xA;&#xD;&#xA;&lt;div class=&#34;video&#34;&gt;&#xD;&#xA;  &lt;iframe src=&#34;https://www.youtube.com/embed/i9VKYozDCvU?controls=1&amp;rel=0&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&#xA;I wanted to use the position of the controllers to influence the particle system. This effect is kind of like in games when the player gets a power up. When I raised my controllers the particles would elevate to a higher degree and spiral outward. When my controllers were low to the ground they wouldn&amp;rsquo;t elevate that much. The direction of the vortex is created depending on the location of the controllers whether they are to the right or the left of the main center position. The user is in control, creating a mist of particles.&#xA;This was the combination of multiple tutos on youtube to track the controllers input thus why you have also the tentacle life moving thing that grows depending on the distance between the L and R controller.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Les Abysses et La Laisse de mer</title>
      <link>https://evann362.github.io/posts/xrdev03/</link>
      <pubDate>Sat, 04 May 2024 00:10:37 +0100</pubDate>
      <guid>https://evann362.github.io/posts/xrdev03/</guid>
      <description>&lt;p&gt;While at the LOREM we collaborated with Galerie Abstract Project to implement a glimpse of our internal projects. Augemented Reality and UV images were integrated into the Abyss Expo&#xA;.&#xA;The artists wanted to gather various objects that we&amp;rsquo;d often imagine to be found at the bottom of the sea. Humans leave so many beach items, trash, and trinquets that sink to the very abyss. There was a desire to use Augmented reality which has a way of transforming the experience of the gallery. We settled on QR codes around the space and outside that when scanned revealed signs of growing sea life. Tentacles or wavy seaweed spread all over the gallery and outside.&#xA;The idea came from glancing at my computer when I was working in Touchdesigner following a workflow to build this sort of tentacle-like living thing.&#xA;&#xD;&#xA;&lt;div class=&#34;video&#34;&gt;&#xD;&#xA;  &lt;iframe src=&#34;https://www.youtube.com/embed/liC-rbcEs6c?controls=1&amp;rel=0&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&#xA;This was Touchdesigner so I could not exactly export an animated 3d model for use in Unity. I had searched for a day and a half to figure out how I can reproduce this in Blender with the same fluid mouvement as I got in TD. I&amp;rsquo;d use GeoNodes but it&amp;rsquo;s hard to export a model with animation but eventually I came across a tuto on how to animate a flag. Seeing the ability to influence the fabric&amp;rsquo;s bones so fluidly with the physics simulations seemed extremely tedious but when it&amp;rsquo;s done once it&amp;rsquo;s easily tweekable for other projects.&#xA;I built the app in Unity and created several image targets I drew up shortly in the time allotted for this project. The final implementation after I mapped the space and tested in the gallery space was just to implement a video recording function. We provided a selection of UV printed images for exhibiting. Tablets were used to make the experience more shared.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Neige Particles</title>
      <link>https://evann362.github.io/posts/xrdev05/</link>
      <pubDate>Thu, 04 May 2023 00:10:37 +0100</pubDate>
      <guid>https://evann362.github.io/posts/xrdev05/</guid>
      <description>&lt;p&gt;A TouchDesigner projection showcased during Nuit Blanche 2023 at Le LOREM. Searching for interaction in our internal projects using Kinect2. This project makes use of how the digital eye breaks things down to pixels or a times point clouds. One could imagine it&amp;rsquo;s similar to the snow or dust that falls from above. Are we aware of our begining and end as something so tiny as dust? Would we prefer flowers? They are in the ground too. Are we to expire or is posible that we have some essence of ourselves that lives on?&#xA;&#xD;&#xA;  &lt;div class=&#34;video&#34;&gt;&#xD;&#xA;    &lt;iframe src=&#34;https://www.youtube.com/embed/c8PULr95iic?controls=1&amp;rel=0&#34; loading=&#34;lazy&#34;&gt;&lt;/iframe&gt;&#xD;&#xA;  &lt;/div&gt;&#xD;&#xA;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
